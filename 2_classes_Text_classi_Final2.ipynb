{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import digits\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import Imputer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset=pd.read_csv('datasets/tow_classes_tweet.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n",
    "dataset1=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/datasets/ASTD.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n",
    "dataset1=clean(dataset1)\n",
    "dataset2=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/datasets/qrci.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n",
    "dataset2=clean(dataset2)\n",
    "dataset3=pd.read_csv('C:/Users/aas3n17/Desktop/Organized/datasets/Ar_tweet_cleaned_final.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n",
    "dataset3=clean(dataset3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat([dataset1, dataset2, dataset3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2147\n",
       "0    2147\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train, twenty_test = train_test_split(dataset, test_size=0.1)\n",
    "#twenty_train.tail(500)\n",
    "#prints all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3864"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1941\n",
       "0    1923\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    224\n",
       "1    206\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "# Removing stop words\n",
    "def get_stop_words(path):\n",
    "    #\"stop_words.txt\"\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "stop_words = get_stop_words('Arabic_stop_word.txt')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_counts.shape (3864, 16645)\n",
      "X_train_tfidf.shape (3864, 16645)\n"
     ]
    }
   ],
   "source": [
    "    # Extracting features from text files\n",
    "    count_vect = CountVectorizer(stop_words=stop_words)\n",
    "    X_train_counts = count_vect.fit_transform(twenty_train['txt'])\n",
    "    print('X_train_counts.shape', X_train_counts.shape)\n",
    "    # TF-IDF\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    print ('X_train_tfidf.shape',X_train_tfidf.shape)\n",
    "    \n",
    "    # Training Naive Bayes (NB) classifier on training data.\n",
    "    clf = MultinomialNB().fit(X_train_tfidf, twenty_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827906976744186"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
    "# The names ‚Äòvect‚Äô , ‚Äòtfidf‚Äô and ‚Äòclf‚Äô are arbitrary but will be used later.\n",
    "# We will be using the 'text_clf' going forward.\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train['txt'], twenty_train.sentiment)\n",
    "predicted = text_clf.predict(twenty_test['txt'])\n",
    "np.mean(predicted == twenty_test.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB [0.827906976744186, 0.8278138528138528, 0.8238095238095239, 0.8084112149532711, 0.8398058252427184]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = predicted\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"NB\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372093023255814\n",
      "Enhanced NB [0.8372093023255814, 0.8371952142965319, 0.8356807511737089, 0.8090909090909091, 0.8640776699029126]\n"
     ]
    }
   ],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', MultinomialNB(alpha=1e-1))])\n",
    "text_clf = text_clf.fit(twenty_train['txt'], twenty_train.sentiment)\n",
    "# Performance of NB Classifier\n",
    "predicted = text_clf.predict(twenty_test['txt'])\n",
    "print(np.mean(predicted == twenty_test.sentiment))\n",
    "def accuracy():\n",
    "        y_pred = predicted\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\"Enhanced NB\",results)\n",
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 3)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-4)}\n",
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "# To see the best mean score and the params, run the following code\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! üòÑ)\n",
    "# and the corresponding parameters are {‚Äòclf__alpha‚Äô: 0.01, ‚Äòtfidf__use_idf‚Äô: True, ‚Äòvect__ngram_range‚Äô: (1, 2)}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7883720930232558\n",
      " SVM [0.7883720930232558, 0.782440689651338, 0.7465181058495821, 0.8758169934640523, 0.6504854368932039]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training Support Vector Machines - SVM and calculating its performance\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.txt)\n",
    "print(np.mean(predicted_svm == twenty_test.sentiment))\n",
    "def accuracy1():\n",
    "        y_pred = predicted_svm\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\" SVM\",results)\n",
    "accuracy1()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8325581395348837"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enhanceddddddddddddd\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-4, n_iter=5, random_state=42))])\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.txt)\n",
    "y_pred = predicted_svm\n",
    "y_test = twenty_test.sentiment\n",
    "accu=metrics.accuracy_score(y_test, y_pred)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced SVM [0.8325581395348837, 0.8320348950760617, 0.8238095238095239, 0.835, 0.8106796116504854]\n"
     ]
    }
   ],
   "source": [
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"Enhanced SVM\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly doing grid search for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit sentiment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8232558139534883"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NBSVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "train=twenty_train\n",
    "test=twenty_test\n",
    "import re\n",
    "import string\n",
    "re_tok = re.compile(r'([{string.punctuation}‚Äú‚Äù¬®¬´¬ª¬Æ¬¥¬∑¬∫¬Ω¬æ¬ø¬°¬ß¬£‚Ç§‚Äò‚Äô])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,1), tokenizer=tokenize, strip_accents='unicode', use_idf=1 )\n",
    "trn_term_doc = vec.fit_transform(train['txt'])\n",
    "test_term_doc = vec.transform(test['txt'])\n",
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "x = trn_term_doc\n",
    "test_x = test_term_doc\n",
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=4, dual=False)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r\n",
    "\n",
    "label_cols=['sentiment']\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n",
    "    \n",
    "\n",
    "y_test_non_category = test.sentiment\n",
    "y_predict_non_category = preds.round()\n",
    "\n",
    "y_pred = y_predict_non_category\n",
    "y_test = y_test_non_category\n",
    "f1_score = metrics.f1_score(y_test, y_pred)\n",
    "accu=metrics.accuracy_score(y_test, y_pred)\n",
    "accu\n",
    "#print('\\n Testing accuracy is {}'.format(accuracy_score(y_test_non_category, y_predict_non_category)))\n",
    "#print ('\\n F1',f1_score(y_test_non_category,y_predict_non_category, average='weighted'))\n",
    "#print ('\\n Recall:', recall_score(y_test_non_category, y_predict_non_category,average='weighted'))\n",
    "#print ('\\n Precision:', precision_score(y_test_non_category, y_predict_non_category, average='weighted'))\n",
    "#print ('\\n clasification report:\\n', classification_report(y_test_non_category, y_predict_non_category))\n",
    "#print ('\\n confussion matrix:\\n',confusion_matrix(y_test_non_category, y_predict_non_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB-SVM [0.8232558139534883, 0.8225032045015099, 0.8109452736318408, 0.8316326530612245, 0.7912621359223301]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = y_predict_non_category\n",
    "        y_test = y_test_non_category\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\"NB-SVM\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-08-17 00:53:58,983] INFO: loading projection weights from arabic-news.bin\n",
      "[2018-08-17 00:54:01,651] INFO: loaded (159175, 300) matrix from arabic-news.bin\n",
      "[2018-08-17 00:54:01,651] INFO: precomputing L2-norms of word weight vectors\n",
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "[2018-08-17 00:54:03,692] INFO: Tokenizing the training dataset ..\n",
      "[2018-08-17 00:54:03,715] INFO:  ... total 47114 training tokens.\n",
      "[2018-08-17 00:54:03,715] INFO: Tokenizing the testing dataset ..\n",
      "[2018-08-17 00:54:03,731] INFO:  ... total 5132 testing tokens.\n",
      "[2018-08-17 00:54:03,731] INFO: Vectorizing training tokens ..\n",
      "[2018-08-17 00:54:03,937] INFO:  ... total 3864 training\n",
      "[2018-08-17 00:54:03,937] INFO: Vectorizing testing tokens ..\n",
      "[2018-08-17 00:54:03,967] INFO:  ... total 430 testing\n",
      "[2018-08-17 00:54:03,993] INFO: Done loading and vectorizing data.\n",
      "[2018-08-17 00:54:03,993] INFO: --- Sentiment CLASSIFIERS ---\n",
      "[2018-08-17 00:54:03,993] INFO: fitting ... \n",
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "[2018-08-17 00:54:16,698] INFO: results ...\n",
      "[2018-08-17 00:54:16,698] INFO: DONE!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMacAvg. 76.49% F1. 75.78% P. 74.88 R. 76.70 : RandomForestClassifier\n",
      "\tMacAvg. 76.45% F1. 73.82% P. 80.11 R. 68.45 : SGDClassifier\n",
      "\tMacAvg. 75.54% F1. 74.58% P. 74.40 R. 74.76 : LinearSVC\n",
      "\tMacAvg. 72.54% F1. 71.90% P. 70.56 R. 73.30 : NuSVC\n",
      "\tMacAvg. 77.83% F1. 76.54% P. 77.89 R. 75.24 : LogisticRegressionCV\n",
      "\tMacAvg. 73.52% F1. 71.25% P. 74.87 R. 67.96 : GaussianNB\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from logging import info, basicConfig, INFO \n",
    "LOG_HEAD = '[%(asctime)s] %(levelname)s: %(message)s'\n",
    "basicConfig(format=LOG_HEAD, level=INFO)\n",
    "class ArSentiment(object):\n",
    "    def __init__(self, train, test, embeddings_file=None, dataset_file=None, plot_roc=False, split=0.9, detailed=False):\n",
    "        \"\"\"\n",
    "        :param embeddings_file: path to the embeddings file.\n",
    "        :param dataset_file: path to a labeled dataset file.\n",
    "        :param plot_roc: boolean, plot ROC figure.\n",
    "        :param split: float, data split fraction i.e. train | test split (default: 90% | 10%)\n",
    "        :param detailed: boolean, output classifiers' parameters info i.e. name, parameters' value, .. etc.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_file = dataset_file\n",
    "        self.split = split\n",
    "\n",
    "        self.embeddings, self.dimension = self.load_vectors(embeddings_file)\n",
    "\n",
    "        # read dataset\n",
    "        train, test = train, test\n",
    "        train_txt, test_txt = train['txt'], test['txt']\n",
    "        self.y_train = train['sentiment']\n",
    "        self.y_test = test['sentiment']\n",
    "\n",
    "        # -- dataset preprocessing -- #\n",
    "        train_tokens = self.tokenize_data(train_txt, 'training')\n",
    "        test_tokens = self.tokenize_data(test_txt, 'testing')\n",
    "\n",
    "        # -- vectorize training/testing data -- #\n",
    "        train_vectors = self.average_feature_vectors(train_tokens, 'training')\n",
    "        test_vectors = self.average_feature_vectors(test_tokens, 'testing')\n",
    "\n",
    "        # vectorized features\n",
    "        self.X_train = self.remove_nan(train_vectors)\n",
    "        self.X_test = self.remove_nan(test_vectors)\n",
    "\n",
    "        info('Done loading and vectorizing data.')\n",
    "        info(\"--- Sentiment CLASSIFIERS ---\")\n",
    "        info(\"fitting ... \")\n",
    "\n",
    "        # classifiers to use\n",
    "        classifiers = [\n",
    "            RandomForestClassifier(n_estimators=100),\n",
    "            SGDClassifier(loss='log', penalty='l1'),\n",
    "            LinearSVC(C=1e1),\n",
    "            NuSVC(),\n",
    "            LogisticRegressionCV(solver='liblinear'),\n",
    "            GaussianNB(),\n",
    "        ]\n",
    "\n",
    "        self.accuracies = {}\n",
    "\n",
    "        # RUN classifiers\n",
    "        for c in classifiers:\n",
    "            self.classify(c, detailed, plot_roc)\n",
    "\n",
    "        avg_f1 = 0\n",
    "        info('results ...')\n",
    "        for k, v in self.accuracies.items():\n",
    "            string = '\\tMacAvg. {:.2f}% F1. {:.2f}% P. {:.2f} R. {:.2f} : {}'\n",
    "            print(string.format(v[0] * 100, v[1] * 100, v[2] * 100, v[3] * 100, k))\n",
    "            avg_f1 += float(v[1])\n",
    "\n",
    "        #print('OVERALL avg F1 test {:.2f}%'.format((avg_f1 / len(self.accuracies)) * 100))\n",
    "        info(\"DONE!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectors(model_name, binary=True):\n",
    "        \"\"\"load the pre-trained embedding model\"\"\"\n",
    "        if binary:\n",
    "            w2v_model = KeyedVectors.load_word2vec_format(model_name, binary=True)\n",
    "        else:\n",
    "            w2v_model = KeyedVectors.load(model_name)\n",
    "\n",
    "        w2v_model.init_sims(replace=True)  # to save memory\n",
    "        vocab, vector_dim = w2v_model.syn0.shape\n",
    "        return w2v_model, vector_dim\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        \"\"\"\n",
    "        :param text: a paragraph string\n",
    "        :return: a list of words\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                txt = unicode(text, 'utf-8')  # py2\n",
    "            except NameError:\n",
    "                txt = text  # py3\n",
    "            words = wordpunct_tokenize(txt)\n",
    "            length = len(words)\n",
    "        except TypeError:\n",
    "            words, length = ['NA'], 0\n",
    "\n",
    "        return words, length\n",
    "\n",
    "    def tokenize_data(self, examples_txt, type_='NaN'):\n",
    "        tokens = []\n",
    "        info('Tokenizing the {} dataset ..'.format(type_))\n",
    "        total_tokens = []\n",
    "        for txt in examples_txt:\n",
    "            words, num = self.tokenize(txt)\n",
    "            tokens.append(words)\n",
    "            total_tokens.append(num)\n",
    "        info(' ... total {} {} tokens.'.format(sum(total_tokens), type_))\n",
    "        return tokens\n",
    "\n",
    "    def feature(self, words):\n",
    "        \"\"\"average words' vectors\"\"\"\n",
    "\n",
    "        feature_vec = np.zeros((self.dimension,), dtype=\"float32\")\n",
    "        retrieved_words = 0\n",
    "        for token in words:\n",
    "            try:\n",
    "                feature_vec = np.add(feature_vec, self.embeddings[token])\n",
    "                retrieved_words += 1\n",
    "            except KeyError:\n",
    "                pass  # if a word is not in the embeddings' vocabulary discard it\n",
    "\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        feature_vec = np.divide(feature_vec, retrieved_words)\n",
    "\n",
    "        return feature_vec\n",
    "\n",
    "    def average_feature_vectors(self, examples, type_='NaN'):\n",
    "        \"\"\"\n",
    "        :param examples: a list of lists (each list contains words) e.g. [['hi','do'], ['you','see'], ... ]\n",
    "        :param type_: (optional) type of examples text e.g. train / test\n",
    "        :return: the average word vector of each list\n",
    "        \"\"\"\n",
    "\n",
    "        feature_vectors = np.zeros((len(examples), self.dimension), dtype=\"float32\")\n",
    "        info(\"Vectorizing {} tokens ..\".format(type_))\n",
    "        for i, example in enumerate(examples):\n",
    "            feature_vectors[i] = self.feature(example)\n",
    "\n",
    "        info(\" ... total {} {}\".format(len(feature_vectors), type_))\n",
    "\n",
    "        return feature_vectors\n",
    "\n",
    "    def classify(self, classifier=None, info_=False, plot_roc=False):\n",
    "\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "\n",
    "        if info_:\n",
    "            info('fitting data ...')\n",
    "            info('\\n\\ncreated \\n\\n{}'.format(classifier))\n",
    "\n",
    "        classifier.fit(self.X_train, self.y_train)\n",
    "        pscore = classifier.score(self.X_test, self.y_test)\n",
    "\n",
    "        if info_:\n",
    "            info('\\n\\n\\t{}() ACCURACY: {}\\n'.format(classifier_name, pscore))\n",
    "\n",
    "        # F1 score\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        f1_score = metrics.f1_score(self.y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(self.y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(self.y_test, y_pred)\n",
    "        precision = metrics.precision_score(self.y_test, y_pred)\n",
    "\n",
    "        results = [macc, f1_score, precision, recall]\n",
    "        self.accuracies[classifier_name] = results\n",
    "\n",
    "        # prediction\n",
    "        negative = len(classifier.predict(self.X_test)[classifier.predict(self.X_test) == 0])\n",
    "        positive = len(classifier.predict(self.X_test)[classifier.predict(self.X_test) == 1])\n",
    "\n",
    "        if plot_roc:\n",
    "            info('plotting roc of ... {}'.format(classifier_name))\n",
    "            self.plot_auc(classifier, classifier_name, negative, positive)\n",
    "\n",
    "    def plot_auc(self, estimator, estimator_name, neg, pos):\n",
    "        try:\n",
    "            classifier_probas = estimator.decision_function(self.X_test)\n",
    "        except AttributeError:\n",
    "            classifier_probas = estimator.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        false_positive_r, true_positive_r, thresholds = metrics.roc_curve(self.y_test, classifier_probas)\n",
    "        roc_auc = metrics.auc(false_positive_r, true_positive_r)\n",
    "\n",
    "        label = '{:.1f}% neg:{} pos:{} {}'.format(roc_auc * 100, neg, pos, estimator_name)\n",
    "        plt.plot(false_positive_r, true_positive_r, label=label)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.title('ROC score(s)')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right', prop={'size': 10})\n",
    "        plt.savefig(\"ROC.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.grid()\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_nan(x):\n",
    "        \"\"\"remove NaN values from data vectors\"\"\"\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "        x_clean = imp.fit_transform(x)\n",
    "        return x_clean\n",
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument(\"embeddings/arabic-news.bin\", help=\"path a pre-trained vectors model.\")\n",
    "    #parser.add_argument(\"datasets/LABR-book-reviews.csv\", help=\"path a labeled (0/1) sentiment dataset.\")\n",
    "\n",
    "    #args = parser.parse_args()\n",
    "    #vec = args.vectors\n",
    "\n",
    "    # vectors file\n",
    "    embeddings_path = \"arabic-news.bin\"\n",
    "    # dataset file\n",
    "    dataset_path =  \"datasets/Aziz/datasets/astd-artwitter.csv\"\n",
    "\n",
    "    # run\n",
    "    ArSentiment(train, test, embeddings_path, dataset_path, plot_roc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3477 samples, validate on 387 samples\n",
      "Epoch 1/30\n",
      "3477/3477 [==============================] - 10s 3ms/step - loss: 0.6655 - acc: 0.6175 - val_loss: 0.5943 - val_acc: 0.6951\n",
      "Epoch 2/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.4023 - acc: 0.8332 - val_loss: 0.4918 - val_acc: 0.7674\n",
      "Epoch 3/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.1837 - acc: 0.9344 - val_loss: 0.6019 - val_acc: 0.7674\n",
      "Epoch 4/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.1034 - acc: 0.9635 - val_loss: 0.6702 - val_acc: 0.7674\n",
      "Epoch 5/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0756 - acc: 0.9715 - val_loss: 0.8677 - val_acc: 0.7649\n",
      "Epoch 6/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0601 - acc: 0.9796 - val_loss: 0.8405 - val_acc: 0.7545\n",
      "Epoch 7/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0509 - acc: 0.9825 - val_loss: 0.9845 - val_acc: 0.7519\n",
      "Epoch 8/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0451 - acc: 0.9825 - val_loss: 0.9889 - val_acc: 0.7597\n",
      "Epoch 9/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0405 - acc: 0.9848 - val_loss: 1.1941 - val_acc: 0.7519\n",
      "Epoch 10/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0461 - acc: 0.9819 - val_loss: 1.0904 - val_acc: 0.7804\n",
      "Epoch 11/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0329 - acc: 0.9873 - val_loss: 1.2068 - val_acc: 0.7623\n",
      "Epoch 12/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0323 - acc: 0.9856 - val_loss: 1.1652 - val_acc: 0.7597\n",
      "Epoch 13/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0333 - acc: 0.9865 - val_loss: 1.2130 - val_acc: 0.7597\n",
      "Epoch 14/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0314 - acc: 0.9833 - val_loss: 1.1764 - val_acc: 0.7726\n",
      "Epoch 15/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0268 - acc: 0.9885 - val_loss: 1.2586 - val_acc: 0.7674\n",
      "Epoch 16/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0258 - acc: 0.9894 - val_loss: 1.4097 - val_acc: 0.7674\n",
      "Epoch 17/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0252 - acc: 0.9905 - val_loss: 1.4878 - val_acc: 0.7649\n",
      "Epoch 18/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0259 - acc: 0.9868 - val_loss: 1.3342 - val_acc: 0.7649\n",
      "Epoch 19/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0249 - acc: 0.9873 - val_loss: 1.3584 - val_acc: 0.7597\n",
      "Epoch 20/30\n",
      "3477/3477 [==============================] - 9s 2ms/step - loss: 0.0245 - acc: 0.9891 - val_loss: 1.4909 - val_acc: 0.7623\n",
      "Epoch 21/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0202 - acc: 0.9902 - val_loss: 1.4984 - val_acc: 0.7545\n",
      "Epoch 22/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0220 - acc: 0.9894 - val_loss: 1.5701 - val_acc: 0.7597\n",
      "Epoch 23/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0228 - acc: 0.9888 - val_loss: 1.6207 - val_acc: 0.7623\n",
      "Epoch 24/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0211 - acc: 0.9902 - val_loss: 1.6630 - val_acc: 0.7571\n",
      "Epoch 25/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0199 - acc: 0.9914 - val_loss: 1.7338 - val_acc: 0.7468\n",
      "Epoch 26/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0198 - acc: 0.9899 - val_loss: 1.7405 - val_acc: 0.7519\n",
      "Epoch 27/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0201 - acc: 0.9896 - val_loss: 1.8518 - val_acc: 0.7468\n",
      "Epoch 28/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0196 - acc: 0.9902 - val_loss: 1.8343 - val_acc: 0.7597\n",
      "Epoch 29/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0212 - acc: 0.9879 - val_loss: 1.6743 - val_acc: 0.7623\n",
      "Epoch 30/30\n",
      "3477/3477 [==============================] - 9s 3ms/step - loss: 0.0196 - acc: 0.9885 - val_loss: 1.6983 - val_acc: 0.7623\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "def get_stop_words():\n",
    "    path = \"Arabic_stop_word.txt\"\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "\n",
    "def list_seq(train, test):\n",
    "    stop_words = get_stop_words()\n",
    "    list_sentences_train = train[\"txt\"]\n",
    "    list_sentences_test = test[\"txt\"]\n",
    "    max_features = 8000\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "    list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "    list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "    return list_tokenized_train, list_tokenized_test\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy1(X_test, y_test):\n",
    "        # F1 score\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred=y_pred.round()\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"macc, f1_score, precision, recall\", results)\n",
    "\n",
    "\n",
    "def model_history(train, test,list_tokenized_train, list_tokenized_test, epochs, batch_size):\n",
    "    list_classes = [\"sentiment\"]\n",
    "    y = train['sentiment']\n",
    "    maxlen = 85 # you can tune\n",
    "    X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "    X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "    inp = Input(shape=(maxlen, )) \n",
    "    max_features = 8000\n",
    "\n",
    "    embed_size = 300 #you can tune\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = LSTM(30, return_sequences=True,name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    history=model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    return history, model, X_te\n",
    "\n",
    "\n",
    "list_tokenized_train, list_tokenized_test=list_seq(train, test)\n",
    "    #word_dis(list_tokenized_train)\n",
    "history, model, X_te= model_history(train, test,list_tokenized_train, list_tokenized_test,30,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macc, f1_score, precision, recall [0.7813953488372093, 0.781011615811373, 0.7718446601941746, 0.7718446601941747, 0.7718446601941747]\n"
     ]
    }
   ],
   "source": [
    "y_true = test['sentiment']\n",
    "calculate_accuracy1(X_te, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def clean(df):\n",
    "        path = \"Arabic_stop_word.txt\"\n",
    "        stop_words = []\n",
    "        with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "            stop_words = myfile.readlines()\n",
    "        stop_words = [word.strip() for word in stop_words]\n",
    "        arabic_punctuations = '''ÿõ<>_()*ÿå&^%][ŸÄÿå/:\"ÿüŸÄ`√∑√ó.,'{}~¬¶+|!‚Äù‚Ä¶‚Äú‚Äì_'''\n",
    "        english_punctuations = string.punctuation\n",
    "        punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "        arabic_diacritics = re.compile(\"\"\"\n",
    "                             Ÿë    | # Tashdid\n",
    "                             Ÿé    | # Fatha\n",
    "                             Ÿã    | # Tanwin Fath\n",
    "                             Ÿè    | # Damma\n",
    "                             Ÿå    | # Tanwin Damm\n",
    "                             Ÿê    | # Kasra\n",
    "                             Ÿç    | # Tanwin Kasr\n",
    "                             Ÿí    | # Sukun\n",
    "                             ŸÄ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "        for comments in df:\n",
    "            # removearabic_diacritics\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(arabic_diacritics,'',str(x)))\n",
    "\n",
    "            #def normalize_arabic(text)\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"[ÿ•ÿ£ÿ¢ÿß]\", \"ÿß\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ÿ§\", \"ÿ°\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"Ÿâ\", \"Ÿä\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ÿ¶\", \"ÿ°\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ÿ©\", \"Ÿá\",str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"⁄Ø\", \"ŸÉ\",str(x)))\n",
    "\n",
    "            \n",
    "\n",
    "            #def remove_punctuations(text):\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"[\"+punctuations_list+\"]\",'',str(x)))\n",
    "\n",
    "            # remove_repeating_char(text):\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(r'(.)\\1+', r'\\1', str(x)))\n",
    "            # remove '\\\\n'\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('\\\\n',' ',str(x)))\n",
    "\n",
    "            # remove any text starting with User... \n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"\\[\\[User.*\",'',str(x)))\n",
    "\n",
    "            # remove IP addresses or user IDs\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",'',str(x)))\n",
    "\n",
    "            # lower uppercase letters\n",
    "            #df['txt'] = df['txt'].map(lambda x: str(x).lower())\n",
    "\n",
    "            #remove http links in the text\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"(http://.*?\\s)|(http://.*)\",'',str(x)))\n",
    "\n",
    "            #remove all punctuation\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"_\", '',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"¬´\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"¬ª\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚Äú\", ' ',str(x))) \n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚Äù\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üòû\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üòî\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üòÇ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üåπ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚ú®\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üëâ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üëà\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚òπ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"üëá\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"⁄©\", 'ŸÉ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚Äî\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"·Éö\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚ïπ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚ó°\", ' ',str(x)))\n",
    "            \n",
    "            \n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚ô•\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚ô°\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"¬•\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"ÿü\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"!\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"#\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"$\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"%\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"&\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"‚úñ\", ' ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ÿ©', 'Ÿá',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(' ÿ¶', 'ÿ°',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ÿ§', 'ÿ°',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('€í', 'ŸÉ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('⁄™', 'ŸÉ',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ÿ£', 'ÿß',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ÿ•', 'ÿß',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub('ÿ¢', 'ÿß',str(x)))\n",
    "\n",
    "            df['txt']= df['txt'].map(lambda x: re.sub(\"[\"+string.punctuation+\"]\",'',str(x)))\n",
    "            df['txt']= df['txt'].map(lambda x: re.sub(\"[\"+punctuations_list+\"]\",'',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(\"[\"+digits+\"]\",'',str(x)))\n",
    "\n",
    "            #df['txt'] = df['txt'].map(lambda x: re.sub(r'[^\\x600-\\x6ff]','',str(x)))\n",
    "            df['txt'] = df['txt'].map(lambda x: re.sub(r'[a-zA-Z?]','',str(x))) \n",
    "            df['txt'].apply(lambda x: [item for item in x if item not in stop_words])\n",
    "        return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
