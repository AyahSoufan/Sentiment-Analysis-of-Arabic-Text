{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data set - training data.\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import Imputer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset=pd.read_csv('datasets/tow_classes_tweet.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n",
    "dataset=pd.read_csv('datasets/Ar_tweet_cleaned_final.csv', encoding='utf-8', usecols=['sentiment', 'txt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    993\n",
       "0    958\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>ÿßÿ≥ÿßŸÑ ÿßŸÑŸá ÿπÿ≤Ÿàÿ¨ŸÑ ŸÑŸá ÿßŸÑÿ´ÿ®ÿßÿ™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "      <td>Ôªø ŸàÿßŸÑŸá ŸÖÿß Ÿäÿ≠ÿ± ÿπÿ≤ÿ®ÿ™ ÿ®ŸÜŸÇÿßŸÑŸäŸá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>1</td>\n",
       "      <td>Ôªøÿµÿ®ÿßÿ≠ ÿßŸÑŸàŸÅÿßÿ° ŸÑŸÉ Ÿäÿß ÿµÿØŸäŸÇŸä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>1</td>\n",
       "      <td>ÔªøŸÇÿµŸá ÿ¨ŸÖŸäŸÑŸá ÿ¨ÿØÿß ÿ™ÿπŸÉÿ≥ ŸÖÿπŸÜŸä ÿßŸÑÿßŸäŸÖÿßŸÜ Ÿà ÿßŸÑÿ™ŸÖÿ≥ŸÉ ÿ®ÿßŸÑÿπ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>ŸàŸÇÿπŸÜÿß ŸàŸÑÿß ŸÖÿß ŸàŸÇÿπŸÜÿß ŸäŸÑŸä ÿ®ÿØŸáŸÖ ŸäÿπŸÖŸÑŸàŸá ÿ®ŸäÿπŸÖŸÑŸàŸá</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentiment                                                txt\n",
       "392          1                         ÿßÿ≥ÿßŸÑ ÿßŸÑŸá ÿπÿ≤Ÿàÿ¨ŸÑ ŸÑŸá ÿßŸÑÿ´ÿ®ÿßÿ™  \n",
       "161          0                       Ôªø ŸàÿßŸÑŸá ŸÖÿß Ÿäÿ≠ÿ± ÿπÿ≤ÿ®ÿ™ ÿ®ŸÜŸÇÿßŸÑŸäŸá  \n",
       "851          1                         Ôªøÿµÿ®ÿßÿ≠ ÿßŸÑŸàŸÅÿßÿ° ŸÑŸÉ Ÿäÿß ÿµÿØŸäŸÇŸä  \n",
       "905          1  ÔªøŸÇÿµŸá ÿ¨ŸÖŸäŸÑŸá ÿ¨ÿØÿß ÿ™ÿπŸÉÿ≥ ŸÖÿπŸÜŸä ÿßŸÑÿßŸäŸÖÿßŸÜ Ÿà ÿßŸÑÿ™ŸÖÿ≥ŸÉ ÿ®ÿßŸÑÿπ...\n",
       "174          0       ŸàŸÇÿπŸÜÿß ŸàŸÑÿß ŸÖÿß ŸàŸÇÿπŸÜÿß ŸäŸÑŸä ÿ®ÿØŸáŸÖ ŸäÿπŸÖŸÑŸàŸá ÿ®ŸäÿπŸÖŸÑŸàŸá  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train, twenty_test = train_test_split(dataset, test_size=0.1)\n",
    "twenty_train.head()\n",
    "#prints all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    899\n",
       "0    856\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    109\n",
       "1     87\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "# Removing stop words\n",
    "def get_stop_words(path):\n",
    "    #\"stop_words.txt\"\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "stop_words = get_stop_words('Arabic_stop_word.txt')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words=stop_words)), ('tfidf', TfidfTransformer()), \n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_counts.shape (1755, 5656)\n",
      "X_train_tfidf.shape (1755, 5656)\n"
     ]
    }
   ],
   "source": [
    "    # Extracting features from text files\n",
    "    count_vect = CountVectorizer(stop_words=stop_words)\n",
    "    X_train_counts = count_vect.fit_transform(twenty_train['txt'])\n",
    "    print('X_train_counts.shape', X_train_counts.shape)\n",
    "    # TF-IDF\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    print ('X_train_tfidf.shape',X_train_tfidf.shape)\n",
    "    \n",
    "    # Training Naive Bayes (NB) classifier on training data.\n",
    "    clf = MultinomialNB().fit(X_train_tfidf, twenty_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8418367346938775"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
    "# The names ‚Äòvect‚Äô , ‚Äòtfidf‚Äô and ‚Äòclf‚Äô are arbitrary but will be used later.\n",
    "# We will be using the 'text_clf' going forward.\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train['txt'], twenty_train.sentiment)\n",
    "predicted = text_clf.predict(twenty_test['txt'])\n",
    "np.mean(predicted == twenty_test.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB [0.8418367346938775, 0.8417337396785705, 0.845771144278607, 0.794392523364486, 0.9042553191489362]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = predicted\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"NB\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8673469387755102\n",
      "Enhanced NB [0.8673469387755102, 0.8673469387755102, 0.8673469387755102, 0.8333333333333334, 0.9042553191489362]\n"
     ]
    }
   ],
   "source": [
    "# Enhancedddddddddddd\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))), ('tfidf', TfidfTransformer(use_idf=False)), ('clf', MultinomialNB(alpha=1e-2))])\n",
    "text_clf = text_clf.fit(twenty_train['txt'], twenty_train.sentiment)\n",
    "# Performance of NB Classifier\n",
    "predicted = text_clf.predict(twenty_test['txt'])\n",
    "print(np.mean(predicted == twenty_test.sentiment))\n",
    "def accuracy():\n",
    "        y_pred = predicted\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\"Enhanced NB\",results)\n",
    "accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.01, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 3)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-4)}\n",
    "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
    "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "# To see the best mean score and the params, run the following code\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_\n",
    "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! üòÑ)\n",
    "# and the corresponding parameters are {‚Äòclf__alpha‚Äô: 0.01, ‚Äòtfidf__use_idf‚Äô: True, ‚Äòvect__ngram_range‚Äô: (1, 2)}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826530612244898\n",
      " SVM [0.826530612244898, 0.8262411347517731, 0.8191489361702128, 0.8191489361702128, 0.8191489361702128]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Training Support Vector Machines - SVM and calculating its performance\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.txt)\n",
    "print(np.mean(predicted_svm == twenty_test.sentiment))\n",
    "def accuracy1():\n",
    "        y_pred = predicted_svm\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\" SVM\",results)\n",
    "accuracy1()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8418367346938775"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enhanceddddddddddddd\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))), ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-4, n_iter=5, random_state=42))])\n",
    "text_clf_svm = text_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.txt)\n",
    "np.mean(predicted_svm == twenty_test.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced SVM [0.8418367346938775, 0.8418326174671353, 0.841025641025641, 0.8118811881188119, 0.8723404255319149]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = predicted_svm\n",
    "        y_test = twenty_test.sentiment\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"Enhanced SVM\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarly doing grid search for SVM\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(twenty_train.txt, twenty_train.sentiment)\n",
    "gs_clf_svm.best_score_\n",
    "gs_clf_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit sentiment\n"
     ]
    }
   ],
   "source": [
    "#NBSVM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "train=twenty_train\n",
    "test=twenty_test\n",
    "import re\n",
    "import string\n",
    "re_tok = re.compile(r'([{string.punctuation}‚Äú‚Äù¬®¬´¬ª¬Æ¬¥¬∑¬∫¬Ω¬æ¬ø¬°¬ß¬£‚Ç§‚Äò‚Äô])')\n",
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "n = train.shape[0]\n",
    "vec = TfidfVectorizer(ngram_range=(1,3), tokenizer=tokenize, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "trn_term_doc = vec.fit_transform(train['txt'])\n",
    "test_term_doc = vec.transform(test['txt'])\n",
    "def pr(y_i, y):\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p+1) / ((y==y_i).sum()+1)\n",
    "x = trn_term_doc\n",
    "test_x = test_term_doc\n",
    "def get_mdl(y):\n",
    "    y = y.values\n",
    "    r = np.log(pr(1,y) / pr(0,y))\n",
    "    m = LogisticRegression(C=3, dual=True)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r\n",
    "\n",
    "label_cols=['sentiment']\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "for i, j in enumerate(label_cols):\n",
    "    print('fit', j)\n",
    "    m,r = get_mdl(train[j])\n",
    "    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n",
    "    \n",
    "\n",
    "y_test_non_category = test.sentiment\n",
    "y_predict_non_category = preds.round()\n",
    "\n",
    "#print('\\n Testing accuracy is {}'.format(accuracy_score(y_test_non_category, y_predict_non_category)))\n",
    "#print ('\\n F1',f1_score(y_test_non_category,y_predict_non_category, average='weighted'))\n",
    "#print ('\\n Recall:', recall_score(y_test_non_category, y_predict_non_category,average='weighted'))\n",
    "#print ('\\n Precision:', precision_score(y_test_non_category, y_predict_non_category, average='weighted'))\n",
    "#print ('\\n clasification report:\\n', classification_report(y_test_non_category, y_predict_non_category))\n",
    "#print ('\\n confussion matrix:\\n',confusion_matrix(y_test_non_category, y_predict_non_category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB-SVM [0.8469387755102041, 0.846683354192741, 0.8404255319148938, 0.8404255319148937, 0.8404255319148937]\n"
     ]
    }
   ],
   "source": [
    "        y_pred = y_predict_non_category\n",
    "        y_test = y_test_non_category\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "        results = [accu, macc, f1_score, precision, recall]\n",
    "        print(\"NB-SVM\",results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2018-08-16 20:37:20,419] INFO: loading projection weights from arabic-news.bin\n",
      "[2018-08-16 20:37:22,976] INFO: loaded (159175, 300) matrix from arabic-news.bin\n",
      "[2018-08-16 20:37:22,976] INFO: precomputing L2-norms of word weight vectors\n",
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "[2018-08-16 20:37:24,936] INFO: Tokenizing the training dataset ..\n",
      "[2018-08-16 20:37:24,951] INFO:  ... total 15995 training tokens.\n",
      "[2018-08-16 20:37:24,951] INFO: Tokenizing the testing dataset ..\n",
      "[2018-08-16 20:37:24,951] INFO:  ... total 1841 testing tokens.\n",
      "[2018-08-16 20:37:24,951] INFO: Vectorizing training tokens ..\n",
      "[2018-08-16 20:37:25,040] INFO:  ... total 1755 training\n",
      "[2018-08-16 20:37:25,040] INFO: Vectorizing testing tokens ..\n",
      "[2018-08-16 20:37:25,058] INFO:  ... total 196 testing\n",
      "[2018-08-16 20:37:25,078] INFO: Done loading and vectorizing data.\n",
      "[2018-08-16 20:37:25,078] INFO: --- Sentiment CLASSIFIERS ---\n",
      "[2018-08-16 20:37:25,078] INFO: fitting ... \n",
      "C:\\Users\\aas3n17\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "[2018-08-16 20:37:29,570] INFO: results ...\n",
      "[2018-08-16 20:37:29,570] INFO: DONE!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMacAvg. 82.59% F1. 81.52% P. 83.33 R. 79.79 : RandomForestClassifier\n",
      "\tMacAvg. 84.18% F1. 84.26% P. 80.58 R. 88.30 : SGDClassifier\n",
      "\tMacAvg. 85.19% F1. 84.66% P. 84.21 R. 85.11 : LinearSVC\n",
      "\tMacAvg. 83.16% F1. 82.90% P. 80.81 R. 85.11 : NuSVC\n",
      "\tMacAvg. 83.67% F1. 83.51% P. 81.00 R. 86.17 : LogisticRegressionCV\n",
      "\tMacAvg. 65.97% F1. 69.44% P. 61.48 R. 79.79 : GaussianNB\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from logging import info, basicConfig, INFO \n",
    "LOG_HEAD = '[%(asctime)s] %(levelname)s: %(message)s'\n",
    "basicConfig(format=LOG_HEAD, level=INFO)\n",
    "class ArSentiment(object):\n",
    "    def __init__(self, train, test, embeddings_file=None, dataset_file=None, plot_roc=False, split=0.9, detailed=False):\n",
    "        \"\"\"\n",
    "        :param embeddings_file: path to the embeddings file.\n",
    "        :param dataset_file: path to a labeled dataset file.\n",
    "        :param plot_roc: boolean, plot ROC figure.\n",
    "        :param split: float, data split fraction i.e. train | test split (default: 90% | 10%)\n",
    "        :param detailed: boolean, output classifiers' parameters info i.e. name, parameters' value, .. etc.\n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_file = dataset_file\n",
    "        self.split = split\n",
    "\n",
    "        self.embeddings, self.dimension = self.load_vectors(embeddings_file)\n",
    "\n",
    "        # read dataset\n",
    "        train, test = train, test\n",
    "        train_txt, test_txt = train['txt'], test['txt']\n",
    "        self.y_train = train['sentiment']\n",
    "        self.y_test = test['sentiment']\n",
    "\n",
    "        # -- dataset preprocessing -- #\n",
    "        train_tokens = self.tokenize_data(train_txt, 'training')\n",
    "        test_tokens = self.tokenize_data(test_txt, 'testing')\n",
    "\n",
    "        # -- vectorize training/testing data -- #\n",
    "        train_vectors = self.average_feature_vectors(train_tokens, 'training')\n",
    "        test_vectors = self.average_feature_vectors(test_tokens, 'testing')\n",
    "\n",
    "        # vectorized features\n",
    "        self.X_train = self.remove_nan(train_vectors)\n",
    "        self.X_test = self.remove_nan(test_vectors)\n",
    "\n",
    "        info('Done loading and vectorizing data.')\n",
    "        info(\"--- Sentiment CLASSIFIERS ---\")\n",
    "        info(\"fitting ... \")\n",
    "\n",
    "        # classifiers to use\n",
    "        classifiers = [\n",
    "            RandomForestClassifier(n_estimators=100),\n",
    "            SGDClassifier(loss='log', penalty='l1'),\n",
    "            LinearSVC(C=1e1),\n",
    "            NuSVC(),\n",
    "            LogisticRegressionCV(solver='liblinear'),\n",
    "            GaussianNB(),\n",
    "        ]\n",
    "\n",
    "        self.accuracies = {}\n",
    "\n",
    "        # RUN classifiers\n",
    "        for c in classifiers:\n",
    "            self.classify(c, detailed, plot_roc)\n",
    "\n",
    "        avg_f1 = 0\n",
    "        info('results ...')\n",
    "        for k, v in self.accuracies.items():\n",
    "            string = '\\tMacAvg. {:.2f}% F1. {:.2f}% P. {:.2f} R. {:.2f} : {}'\n",
    "            print(string.format(v[0] * 100, v[1] * 100, v[2] * 100, v[3] * 100, k))\n",
    "            avg_f1 += float(v[1])\n",
    "\n",
    "        #print('OVERALL avg F1 test {:.2f}%'.format((avg_f1 / len(self.accuracies)) * 100))\n",
    "        info(\"DONE!\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vectors(model_name, binary=True):\n",
    "        \"\"\"load the pre-trained embedding model\"\"\"\n",
    "        if binary:\n",
    "            w2v_model = KeyedVectors.load_word2vec_format(model_name, binary=True)\n",
    "        else:\n",
    "            w2v_model = KeyedVectors.load(model_name)\n",
    "\n",
    "        w2v_model.init_sims(replace=True)  # to save memory\n",
    "        vocab, vector_dim = w2v_model.syn0.shape\n",
    "        return w2v_model, vector_dim\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize(text):\n",
    "        \"\"\"\n",
    "        :param text: a paragraph string\n",
    "        :return: a list of words\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                txt = unicode(text, 'utf-8')  # py2\n",
    "            except NameError:\n",
    "                txt = text  # py3\n",
    "            words = wordpunct_tokenize(txt)\n",
    "            length = len(words)\n",
    "        except TypeError:\n",
    "            words, length = ['NA'], 0\n",
    "\n",
    "        return words, length\n",
    "\n",
    "    def tokenize_data(self, examples_txt, type_='NaN'):\n",
    "        tokens = []\n",
    "        info('Tokenizing the {} dataset ..'.format(type_))\n",
    "        total_tokens = []\n",
    "        for txt in examples_txt:\n",
    "            words, num = self.tokenize(txt)\n",
    "            tokens.append(words)\n",
    "            total_tokens.append(num)\n",
    "        info(' ... total {} {} tokens.'.format(sum(total_tokens), type_))\n",
    "        return tokens\n",
    "\n",
    "    def feature(self, words):\n",
    "        \"\"\"average words' vectors\"\"\"\n",
    "\n",
    "        feature_vec = np.zeros((self.dimension,), dtype=\"float32\")\n",
    "        retrieved_words = 0\n",
    "        for token in words:\n",
    "            try:\n",
    "                feature_vec = np.add(feature_vec, self.embeddings[token])\n",
    "                retrieved_words += 1\n",
    "            except KeyError:\n",
    "                pass  # if a word is not in the embeddings' vocabulary discard it\n",
    "\n",
    "        np.seterr(divide='ignore', invalid='ignore')\n",
    "        feature_vec = np.divide(feature_vec, retrieved_words)\n",
    "\n",
    "        return feature_vec\n",
    "\n",
    "    def average_feature_vectors(self, examples, type_='NaN'):\n",
    "        \"\"\"\n",
    "        :param examples: a list of lists (each list contains words) e.g. [['hi','do'], ['you','see'], ... ]\n",
    "        :param type_: (optional) type of examples text e.g. train / test\n",
    "        :return: the average word vector of each list\n",
    "        \"\"\"\n",
    "\n",
    "        feature_vectors = np.zeros((len(examples), self.dimension), dtype=\"float32\")\n",
    "        info(\"Vectorizing {} tokens ..\".format(type_))\n",
    "        for i, example in enumerate(examples):\n",
    "            feature_vectors[i] = self.feature(example)\n",
    "\n",
    "        info(\" ... total {} {}\".format(len(feature_vectors), type_))\n",
    "\n",
    "        return feature_vectors\n",
    "\n",
    "    def classify(self, classifier=None, info_=False, plot_roc=False):\n",
    "\n",
    "        classifier_name = classifier.__class__.__name__\n",
    "\n",
    "        if info_:\n",
    "            info('fitting data ...')\n",
    "            info('\\n\\ncreated \\n\\n{}'.format(classifier))\n",
    "\n",
    "        classifier.fit(self.X_train, self.y_train)\n",
    "        pscore = classifier.score(self.X_test, self.y_test)\n",
    "\n",
    "        if info_:\n",
    "            info('\\n\\n\\t{}() ACCURACY: {}\\n'.format(classifier_name, pscore))\n",
    "\n",
    "        # F1 score\n",
    "        y_pred = classifier.predict(self.X_test)\n",
    "        f1_score = metrics.f1_score(self.y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(self.y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(self.y_test, y_pred)\n",
    "        precision = metrics.precision_score(self.y_test, y_pred)\n",
    "\n",
    "        results = [macc, f1_score, precision, recall]\n",
    "        self.accuracies[classifier_name] = results\n",
    "\n",
    "        # prediction\n",
    "        negative = len(classifier.predict(self.X_test)[classifier.predict(self.X_test) == 0])\n",
    "        positive = len(classifier.predict(self.X_test)[classifier.predict(self.X_test) == 1])\n",
    "\n",
    "        if plot_roc:\n",
    "            info('plotting roc of ... {}'.format(classifier_name))\n",
    "            self.plot_auc(classifier, classifier_name, negative, positive)\n",
    "\n",
    "    def plot_auc(self, estimator, estimator_name, neg, pos):\n",
    "        try:\n",
    "            classifier_probas = estimator.decision_function(self.X_test)\n",
    "        except AttributeError:\n",
    "            classifier_probas = estimator.predict_proba(self.X_test)[:, 1]\n",
    "\n",
    "        false_positive_r, true_positive_r, thresholds = metrics.roc_curve(self.y_test, classifier_probas)\n",
    "        roc_auc = metrics.auc(false_positive_r, true_positive_r)\n",
    "\n",
    "        label = '{:.1f}% neg:{} pos:{} {}'.format(roc_auc * 100, neg, pos, estimator_name)\n",
    "        plt.plot(false_positive_r, true_positive_r, label=label)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([-0.05, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.title('ROC score(s)')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right', prop={'size': 10})\n",
    "        plt.savefig(\"ROC.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.grid()\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_nan(x):\n",
    "        \"\"\"remove NaN values from data vectors\"\"\"\n",
    "        imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "        x_clean = imp.fit_transform(x)\n",
    "        return x_clean\n",
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument(\"embeddings/arabic-news.bin\", help=\"path a pre-trained vectors model.\")\n",
    "    #parser.add_argument(\"datasets/LABR-book-reviews.csv\", help=\"path a labeled (0/1) sentiment dataset.\")\n",
    "\n",
    "    #args = parser.parse_args()\n",
    "    #vec = args.vectors\n",
    "\n",
    "    # vectors file\n",
    "    embeddings_path = \"arabic-news.bin\"\n",
    "    # dataset file\n",
    "    dataset_path =  \"datasets/Aziz/datasets/astd-artwitter.csv\"\n",
    "\n",
    "    # run\n",
    "    ArSentiment(train, test, embeddings_path, dataset_path, plot_roc=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1579 samples, validate on 176 samples\n",
      "Epoch 1/30\n",
      "1579/1579 [==============================] - 6s 4ms/step - loss: 0.6838 - acc: 0.5795 - val_loss: 0.6634 - val_acc: 0.6364\n",
      "Epoch 2/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.5706 - acc: 0.8132 - val_loss: 0.4514 - val_acc: 0.8580\n",
      "Epoch 3/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.2461 - acc: 0.9360 - val_loss: 0.3206 - val_acc: 0.8636\n",
      "Epoch 4/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0875 - acc: 0.9880 - val_loss: 0.3528 - val_acc: 0.8807\n",
      "Epoch 5/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0473 - acc: 0.9956 - val_loss: 0.4062 - val_acc: 0.8750\n",
      "Epoch 6/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0322 - acc: 0.9962 - val_loss: 0.4529 - val_acc: 0.8523\n",
      "Epoch 7/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0263 - acc: 0.9968 - val_loss: 0.4419 - val_acc: 0.8580\n",
      "Epoch 8/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0179 - acc: 0.9987 - val_loss: 0.4950 - val_acc: 0.8409\n",
      "Epoch 9/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0129 - acc: 0.9981 - val_loss: 0.5257 - val_acc: 0.8466\n",
      "Epoch 10/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0115 - acc: 0.9987 - val_loss: 0.5576 - val_acc: 0.8523\n",
      "Epoch 11/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0103 - acc: 0.9994 - val_loss: 0.5591 - val_acc: 0.8466\n",
      "Epoch 12/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.8523\n",
      "Epoch 13/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0069 - acc: 0.9994 - val_loss: 0.6258 - val_acc: 0.8636\n",
      "Epoch 14/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0067 - acc: 0.9994 - val_loss: 0.6066 - val_acc: 0.8523\n",
      "Epoch 15/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0061 - acc: 0.9994 - val_loss: 0.6600 - val_acc: 0.8636\n",
      "Epoch 16/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0061 - acc: 0.9994 - val_loss: 0.6209 - val_acc: 0.8466\n",
      "Epoch 17/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0061 - acc: 0.9987 - val_loss: 0.6460 - val_acc: 0.8523\n",
      "Epoch 18/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.6716 - val_acc: 0.8466\n",
      "Epoch 19/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.6879 - val_acc: 0.8523\n",
      "Epoch 20/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.6903 - val_acc: 0.8523\n",
      "Epoch 21/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.7032 - val_acc: 0.8523\n",
      "Epoch 22/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7525 - val_acc: 0.8466\n",
      "Epoch 23/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7576 - val_acc: 0.8466\n",
      "Epoch 24/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.7757 - val_acc: 0.8409\n",
      "Epoch 25/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7767 - val_acc: 0.8352\n",
      "Epoch 26/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8120 - val_acc: 0.8295\n",
      "Epoch 27/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.8268 - val_acc: 0.8466\n",
      "Epoch 28/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.8358 - val_acc: 0.8409\n",
      "Epoch 29/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.7592 - val_acc: 0.8295\n",
      "Epoch 30/30\n",
      "1579/1579 [==============================] - 4s 3ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.8349 - val_acc: 0.8409\n"
     ]
    }
   ],
   "source": [
    "#LSTM\n",
    "def get_stop_words():\n",
    "    path = \"Arabic_stop_word.txt\"\n",
    "    stop_words = []\n",
    "    with codecs.open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as myfile:\n",
    "        stop_words = myfile.readlines()\n",
    "    stop_words = [word.strip() for word in stop_words]\n",
    "    return stop_words\n",
    "\n",
    "def list_seq(train, test):\n",
    "    stop_words = get_stop_words()\n",
    "    list_sentences_train = train[\"txt\"]\n",
    "    list_sentences_test = test[\"txt\"]\n",
    "    max_features = 8000\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "    list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "    list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "    return list_tokenized_train, list_tokenized_test\n",
    "\n",
    "\n",
    "\n",
    "def calculate_accuracy1(X_test, y_test):\n",
    "        # F1 score\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred=y_pred.round()\n",
    "        f1_score = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "        # macro accuracy (macro average)\n",
    "        macc = metrics.f1_score(y_test, y_pred, pos_label=None, average='macro')\n",
    "\n",
    "        # precision and recall\n",
    "        recall = metrics.recall_score(y_test, y_pred)\n",
    "        precision = metrics.precision_score(y_test, y_pred)\n",
    "        accu=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "        results = [accu,macc, f1_score, precision, recall]\n",
    "        print(\"macc, f1_score, precision, recall\", results)\n",
    "\n",
    "\n",
    "def model_history(train, test,list_tokenized_train, list_tokenized_test, epochs, batch_size):\n",
    "    list_classes = [\"sentiment\"]\n",
    "    y = train['sentiment']\n",
    "    maxlen = 85 # you can tune\n",
    "    X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "    X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "    inp = Input(shape=(maxlen, )) \n",
    "    max_features = 8000\n",
    "\n",
    "    embed_size = 300 #you can tune\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = LSTM(30, return_sequences=True,name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    history=model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "    return history, model, X_te\n",
    "\n",
    "\n",
    "list_tokenized_train, list_tokenized_test=list_seq(train, test)\n",
    "    #word_dis(list_tokenized_train)\n",
    "history, model, X_te= model_history(train, test,list_tokenized_train, list_tokenized_test,30,32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macc, f1_score, precision, recall [0.8163265306122449, 0.815847165674914, 0.8252427184466019, 0.7589285714285714, 0.9042553191489362]\n"
     ]
    }
   ],
   "source": [
    "y_true = test['sentiment']\n",
    "calculate_accuracy1(X_te, y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
